{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarefa 1: DATA APP para Classificador Multiclasse MNIST\n",
    "\n",
    "Este notebook segue os passos da avaliação:\n",
    "a) Avaliar 7 modelos com `cross_val_predict`.\n",
    "b) Ranquear o top 3 por acurácia de CV.\n",
    "c) Aplicar os 7 modelos no conjunto de teste inicial.\n",
    "d) Ranquear o top 3 pela menor diferença (CV vs. Teste) e analisar.\n",
    "e) Realizar `RandomizedSearchCV` no **Top 1** (conforme sugestão do professor para acelerar).\n",
    "f) Aplicar o melhor modelo de 'e' em um *novo* conjunto de teste.\n",
    "g) Exportar o melhor modelo final e o scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 1: Importação das Bibliotecas\n",
    "\n",
    "Aqui, importamos todas as ferramentas necessárias. Isso inclui `numpy` e `pandas` para manipulação de dados, `matplotlib` para gráficos, `sklearn` para carregar dados, pré-processar (StandardScaler), dividir dados (train_test_split), avaliar (cross_val_predict, accuracy_score) e os 7 modelos de classificação solicitados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# Modelos para a etapa 1a\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42) # Define uma semente aleatória para reprodutibilidade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 2: Carga e Divisão Inicial dos Dados\n",
    "\n",
    "Carregamos o dataset MNIST (70.000 imagens 28x28). Seguindo a convenção padrão do MNIST, dividimos os dados:\n",
    "* `X_train_orig` / `y_train_orig`: Os primeiros 60.000 exemplos para treino e validação cruzada.\n",
    "* `X_test1` / `y_test1`: Os últimos 10.000 exemplos como nosso primeiro conjunto de teste (para a etapa 1c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=True, parser='auto')\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(np.uint8)\n",
    "\n",
    "# Divisão original (como nos notebooks de exemplo) - Teste 1\n",
    "X_train_orig, X_test1, y_train_orig, y_test1 = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 3: Padronização dos Dados (Scaler)\n",
    "\n",
    "Muitos modelos (como SVM, MLP, KNN, Regressão Logística) são sensíveis à escala dos dados (pixels de 0 a 255). Usamos `StandardScaler` para padronizar os dados (média 0, desvio padrão 1).\n",
    "\n",
    "**Importante:** Ajustamos (`fit_transform`) o scaler *apenas* nos dados de treino (`X_train_orig`) e depois usamos esse mesmo scaler (com a média e desvio do treino) para transformar (`transform`) o conjunto de teste (`X_test1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalar os dados (essencial para muitos desses modelos)\n",
    "scaler_orig = StandardScaler()\n",
    "X_train_orig_scaled = scaler_orig.fit_transform(X_train_orig)\n",
    "X_test1_scaled = scaler_orig.transform(X_test1)\n",
    "\n",
    "print(f\"Formato Treino Original: {X_train_orig_scaled.shape}\")\n",
    "print(f\"Formato Teste 1: {X_test1_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 4: Etapas 1a & 1b - Avaliação com Validação Cruzada (CV)\n",
    "\n",
    "**Etapa 1a:** Definimos os 7 modelos solicitados, todos com hiperparâmetros *default* (padrão) e `random_state=42` para garantir que os resultados sejam os mesmos em diferentes execuções.\n",
    "\n",
    "**Etapa 1b:** Iteramos sobre cada modelo:\n",
    "1.  Usamos `cross_val_predict(cv=3)` para fazer uma validação cruzada de 3 folds. Isso treina o modelo em 2/3 dos dados e testa no 1/3 restante, repetindo 3 vezes até que todos os dados de treino tenham sido usados como teste uma vez.\n",
    "2.  Calculamos a `accuracy_score` (acurácia global) comparando as predições da CV (`y_train_pred`) com os rótulos reais do treino (`y_train_orig`).\n",
    "3.  Armazenamos os resultados, ordenamos do melhor para o pior e identificamos o **Top 3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os 7 modelos com hiperparâmetros default e random_state para reprodutibilidade\n",
    "models = {\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'MLPClassifier': MLPClassifier(random_state=42, max_iter=300), # Aumentar max_iter para evitar warning\n",
    "    'SVC': SVC(random_state=42),\n",
    "    'LogisticRegression': LogisticRegression(random_state=42, max_iter=1000, n_jobs=-1),\n",
    "    'SGDClassifier': SGDClassifier(random_state=42, n_jobs=-1),\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(n_jobs=-1),\n",
    "    'XGBClassifier': XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss', use_label_encoder=False)\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Iniciando Etapa 1a: Avaliação com cross_val_predict...\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Avaliando {name}...\")\n",
    "    # NOTA: O dataset completo (60k) é usado. SVC e KNN podem levar vários minutos.\n",
    "    y_train_pred = cross_val_predict(model, X_train_orig_scaled, y_train_orig, cv=3, n_jobs=-1)\n",
    "    cv_accuracy = accuracy_score(y_train_orig, y_train_pred)\n",
    "    results.append({'Modelo': name, 'Acurácia CV': cv_accuracy})\n",
    "    print(f\"{name} - Acurácia CV: {cv_accuracy:.4f}\")\n",
    "\n",
    "# Criar DataFrame e ranquear (Etapa 1b)\n",
    "results_df = pd.DataFrame(results).sort_values(by='Acurácia CV', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n--- Etapa 1b: Ranking por Acurácia CV ---\")\n",
    "print(results_df)\n",
    "\n",
    "top_3_cv_models = results_df['Modelo'].head(3).tolist()\n",
    "print(f\"\\nTop 3 Modelos (CV): {top_3_cv_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 5: Etapas 1c & 1d - Avaliação no Teste 1 e Análise de Diferença\n",
    "\n",
    "**Etapa 1c:** Treinamos (fit) cada um dos 7 modelos no conjunto de treino *completo* (`X_train_orig_scaled`, 60k amostras) e aplicamos (predict) no conjunto de teste 1 (`X_test1_scaled`, 10k amostras), que o modelo nunca viu.\n",
    "\n",
    "**Etapa 1d:** Calculamos a diferença absoluta (`Abs(Diferença)`) entre a Acurácia CV (Etapa 1a) e a Acurácia Teste (Etapa 1c). Ranqueamos os modelos pela menor diferença. Isso nos ajuda a ver quais modelos generalizam melhor (ou seja, têm menos overfitting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nIniciando Etapa 1c: Aplicação no Conjunto de Teste 1...\")\n",
    "test_accuracies = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Treinando e Testando {name}...\")\n",
    "    model.fit(X_train_orig_scaled, y_train_orig)\n",
    "    y_test1_pred = model.predict(X_test1_scaled)\n",
    "    test_accuracy = accuracy_score(y_test1, y_test1_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    print(f\"{name} - Acurácia Teste 1: {test_accuracy:.4f}\")\n",
    "\n",
    "results_df['Acurácia Teste'] = test_accuracies\n",
    "results_df['Diferença (CV - Teste)'] = results_df['Acurácia CV'] - results_df['Acurácia Teste']\n",
    "results_df['Abs(Diferença)'] = np.abs(results_df['Diferença (CV - Teste)'])\n",
    "\n",
    "# Ranquear por menor diferença (Etapa 1d)\n",
    "results_df_diff_rank = results_df.sort_values(by='Abs(Diferença)', ascending=True)\n",
    "\n",
    "print(\"\\n--- Etapa 1d: Ranking por Menor Diferença (CV vs. Teste) ---\")\n",
    "print(results_df_diff_rank[['Modelo', 'Acurácia CV', 'Acurácia Teste', 'Abs(Diferença)']])\n",
    "\n",
    "top_3_diff_models = results_df_diff_rank['Modelo'].head(3).tolist()\n",
    "print(f\"\\nTop 3 Modelos (Menor Diferença): {top_3_diff_models}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 6: 1d (Análise)\n",
    "\n",
    "**Análise:** \n",
    "Com base nos resultados (que podem variar dependendo da execução exata e das bibliotecas):\n",
    "\n",
    "* **Top 3 (Acurácia CV):** [A ser preenchido pela execução, ex: 'SVC', 'MLPClassifier', 'KNeighborsClassifier']\n",
    "* **Top 3 (Menor Diferença):** [A ser preenchido, ex: 'SVC', 'LogisticRegression', 'XGBClassifier']\n",
    "\n",
    "**Os modelos coincidem?**\n",
    "(A ser preenchido) Frequentemente, o SVC aparece em ambas as listas, mostrando alta performance *e* boa generalização. Modelos como KNN, embora tenham alta acurácia na CV (por \"memorizar\" o treino), podem ter uma queda maior no teste. Modelos mais simples (como `GaussianNB` ou `SGDClassifier` default) podem ter acurácia baixa, mas também baixa diferença (underfitting), enquanto modelos complexos (como `MLP` ou `XGB` default) podem ter alta acurácia no CV, mas também alta diferença (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 7: Etapa 1e & 1f (Preparação) - Novo Split de Dados\n",
    "\n",
    "Conforme a instrução 'f', precisamos de um *novo* conjunto de teste. Usamos `train_test_split` em todo o dataset (X, y) com `random_state=101` (diferente da divisão original) para criar `X_train_new` e `X_test_new`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Novo Split (usando train_test_split para garantir uma semente diferente)\n",
    "X_train_new, X_test_new, y_train_new, y_test_new = train_test_split(X, y, test_size=10000, random_state=101, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 8: Etapa 1e & 1f (Preparação) - Novo Scaler\n",
    "\n",
    "Criamos um *novo* scaler (`scaler_new`). Ajustamos (`fit_transform`) ele *apenas* aos novos dados de treino (`X_train_new_scaled`) e o usamos para transformar (`transform`) o novo teste (`X_test_new_scaled`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Escalar novos dados\n",
    "scaler_new = StandardScaler()\n",
    "X_train_new_scaled = scaler_new.fit_transform(X_train_new)\n",
    "X_test_new_scaled = scaler_new.transform(X_test_new)\n",
    "\n",
    "print(f\"Formato Novo Treino: {X_train_new_scaled.shape}\")\n",
    "print(f\"Formato Novo Teste: {X_test_new_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 9: Etapa 1e - Definição dos Hiperparâmetros\n",
    "\n",
    "Definimos os hiperparâmetros e as faixas de valores para os 3 melhores modelos da Etapa 1b (`top_3_cv_models`). Usamos distribuições (como `randint`, `loguniform`) para o `RandomizedSearchCV`, que testa combinações aleatórias, sendo mais eficiente que o `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Definir Modelos e Hiperparâmetros para RandomizedSearch (Top 3 da Etapa 1b)\n",
    "\n",
    "from scipy.stats import randint, uniform, loguniform\n",
    "\n",
    "# Dicionário completo de grids de parâmetros\n",
    "param_grids = {\n",
    "    'MLPClassifier': {\n",
    "        'hidden_layer_sizes': [(50,), (100,), (50, 50)],\n",
    "        'alpha': loguniform(1e-4, 1e-1),\n",
    "        'learning_rate_init': loguniform(1e-4, 1e-2)\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': loguniform(1e-1, 1e2),\n",
    "        'gamma': loguniform(1e-4, 1e-1),\n",
    "        'kernel': ['rbf', 'poly']\n",
    "    },\n",
    "    'KNeighborsClassifier': {\n",
    "        'n_neighbors': randint(3, 10),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'C': loguniform(1e-2, 1e2),\n",
    "        'solver': ['saga'],\n",
    "        'penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'SGDClassifier': {\n",
    "        'loss': ['hinge', 'log_loss'],\n",
    "        'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'alpha': loguniform(1e-5, 1e-1)\n",
    "    },\n",
    "    'XGBClassifier': {\n",
    "        'n_estimators': randint(100, 500),\n",
    "        'learning_rate': loguniform(0.01, 0.3),\n",
    "        'max_depth': randint(3, 10)\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'var_smoothing': loguniform(1e-10, 1e-8)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Constantes para a busca (Conforme instrução 'e')\n",
    "N_COMBINACOES = 10 # N=10 combinações\n",
    "CV_FOLDS = 3       # Mesmo número de folds\n",
    "RANDOM_SEED = 42   # Mesma semente\n",
    "\n",
    "best_estimators = []\n",
    "\n",
    "print(f\"\\nIniciando Etapa 1e: RandomizedSearchCV para o Top 1 (Otimização de tempo)...\")\n",
    "print(f\"Melhor modelo da Etapa 1b: {top_3_cv_models[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 10: Etapa 1e (Execução) - RandomizedSearchCV (Otimizado)\n",
    "\n",
    "Conforme a sugestão do professor para acelerar o processo, executamos o `RandomizedSearchCV` **apenas no melhor modelo (Top 1)** da Etapa 1b.\n",
    "\n",
    "1.  Configuramos o `RandomizedSearchCV` com N=10, CV=3, Semente=42.\n",
    "2.  Executamos o `fit` no *novo* conjunto de treino (`X_train_new_scaled`).\n",
    "3.  Salvamos o `best_estimator_` para a próxima etapa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- INÍCIO DA MODIFICAÇÃO (Baseada na Sugestão do Professor) ---\n",
    "# Em vez de iterar nos 3, pegamos apenas o melhor (índice 0)\n",
    "best_model_name = top_3_cv_models[0]\n",
    "\n",
    "if best_model_name not in models or best_model_name not in param_grids:\n",
    "    print(f\"Modelo {best_model_name} não encontrado. Parando.\")\n",
    "else:\n",
    "    print(f\"Iniciando busca para {best_model_name}...\")\n",
    "    base_model = models[best_model_name]\n",
    "    params = param_grids[best_model_name]\n",
    "    \n",
    "    random_search = RandomizedSearchCV(\n",
    "        base_model,\n",
    "        param_distributions=params,\n",
    "        n_iter=N_COMBINACOES,\n",
    "        cv=CV_FOLDS,\n",
    "        random_state=RANDOM_SEED,\n",
    "        n_jobs=-1,\n",
    "        scoring='accuracy'\n",
    "    )\n",
    "    \n",
    "    # 4. Executar a busca no *novo* treino\n",
    "    random_search.fit(X_train_new_scaled, y_train_new)\n",
    "    \n",
    "    print(f\"Melhores parâmetros para {best_model_name}: {random_search.best_params_}\")\n",
    "    print(f\"Melhor acurácia CV ({best_model_name}): {random_search.best_score_:.4f}\")\n",
    "    \n",
    "    # Salva o único estimador otimizado\n",
    "    best_estimators = [random_search.best_estimator_]\n",
    "\n",
    "print(\"\\nBusca de Hiperparâmetros Concluída.\")\n",
    "# --- FIM DA MODIFICAÇÃO ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 11: Etapa 1f - Avaliação do Modelo Otimizado\n",
    "\n",
    "Agora, pegamos o único modelo otimizado (da Etapa 1e) e o aplicamos no `X_test_new_scaled` (o conjunto de teste que foi separado na Etapa 1e e não foi usado na otimização). \n",
    "\n",
    "Isso nos dá a performance final do nosso melhor modelo em dados completamente novos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nIniciando Etapa 1f: Avaliação no Novo Conjunto de Teste...\")\n",
    "final_results = []\n",
    "\n",
    "# Esta lista agora deve conter apenas 1 estimador\n",
    "if not best_estimators:\n",
    "    print(\"Nenhum modelo foi otimizado. Parando.\")\n",
    "else:\n",
    "    model = best_estimators[0]\n",
    "    model_name = model.__class__.__name__\n",
    "    y_test_new_pred = model.predict(X_test_new_scaled)\n",
    "    test_accuracy = accuracy_score(y_test_new, y_test_new_pred)\n",
    "    \n",
    "    print(f\"\\n--- {model_name} (Otimizado) ---\")\n",
    "    print(f\"Acurácia no Novo Teste: {test_accuracy:.4f}\")\n",
    "    print(classification_report(y_test_new, y_test_new_pred))\n",
    "    \n",
    "    final_results.append({'Modelo': model_name, 'Acurácia Novo Teste': test_accuracy, 'Estimador': model})\n",
    "\n",
    "# Determinar o melhor modelo final\n",
    "final_df = pd.DataFrame(final_results).sort_values(by='Acurácia Novo Teste', ascending=False)\n",
    "best_overall_model_info = final_df.iloc[0]\n",
    "best_overall_model = best_overall_model_info['Estimador']\n",
    "\n",
    "print(\"\\n--- Melhor Modelo Geral (Pós-Otimização) ---\")\n",
    "print(best_overall_model_info[['Modelo', 'Acurácia Novo Teste']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Célula 12: Etapa 1g - Exportar o Melhor Modelo e Scaler\n",
    "\n",
    "Finalmente, pegamos o melhor modelo da Etapa 1f (`best_overall_model`) e o `scaler_new` (o scaler que foi ajustado aos dados de treino desse modelo) e os salvamos em arquivos `.joblib`. Esses arquivos podem ser carregados pela aplicação Streamlit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'best_mnist_model.joblib'\n",
    "scaler_filename = 'mnist_scaler.joblib'\n",
    "\n",
    "if best_estimators: # Só salva se o modelo foi treinado\n",
    "    joblib.dump(best_overall_model, model_filename)\n",
    "    joblib.dump(scaler_new, scaler_filename) # Salvar o scaler que foi usado no treino deste modelo\n",
    "\n",
    "    print(f\"\\nEtapa 1g Concluída.\")\n",
    "    print(f\"Melhor modelo salvo em: {model_filename}\")\n",
    "    print(f\"Scaler correspondente salvo em: {scaler_filename}\")\n",
    "else:\n",
    "    print(\"\\nEtapa 1g Falhou: Nenhum modelo foi treinado/otimizado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}